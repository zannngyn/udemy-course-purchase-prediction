import findspark
findspark.init()

from pyspark.sql.types import DoubleType, IntegerType
from pyspark.sql import SparkSession
from pyspark.sql import functions as F
from pyspark.sql.functions import col, when
from tkinter import filedialog, messagebox
import tkinter as tk
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import os

spark = SparkSession.builder.appName("Ph√¢n t√≠ch m√¥ t·∫£").getOrCreate()



# In[ ]:

def resolve_csv_path():
    # cwd l√† ƒë∆∞·ªùng d·∫´n hi·ªán t·∫°i n∆°i ch∆∞∆°ng tr√¨nh Python ƒëang ch·∫°y
    cwd = os.getcwd()
    csv_path = os.path.abspath(os.path.join(cwd, "data/processed/data_cleaned.csv"))
    print("Resolved CSV path:", csv_path)


# In[ ]:

def load_data():
    # In ra th∆∞ m·ª•c hi·ªán t·∫°i ƒë·ªÉ ki·ªÉm tra
    print("Current working directory:", os.getcwd())

    # L·∫•y ƒë∆∞·ªùng d·∫´n ƒë·∫øn file CSV
    csv_path = "data/processed/data_cleaned.csv"
    print("CSV path:", csv_path)

    # Kh·ªüi t·∫°o Spark session
    spark = SparkSession.builder.appName("EDA").getOrCreate()

    # ƒê·ªçc d·ªØ li·ªáu
    df = spark.read.option("header", True).csv(csv_path, inferSchema=True)
    df.show(5)
    df.printSchema()
    return df


# In[ ]:

def cast_numeric_columns(df):
    # C√°c c·ªôt s·ªë c·∫ßn √©p ki·ªÉu
    numeric_columns = {
        "id": DoubleType(),
        "price": DoubleType(),
        "num_subscribers": DoubleType(),
        "avg_rating": DoubleType(),
        "num_reviews": DoubleType(),
        "num_comments": DoubleType(),
        "num_lectures": DoubleType(),
        "content_length_min": DoubleType(),
        "most_common_price": DoubleType(),
        "result": IntegerType()
    }

    # √âp ki·ªÉu an to√†n b·∫±ng c√°ch d√πng h√†m `when` k·∫øt h·ª£p `rlike`
    for col, dtype in numeric_columns.items():
        if col in df.columns:
            # ch·ªâ cast n·∫øu d·ªØ li·ªáu l√† d·∫°ng s·ªë, c√≤n l·∫°i th√†nh None
            df = df.withColumn(
                col,
                F.when(F.col(col).rlike(r'^\d+(\.\d+)?$'), F.col(col).cast(dtype)).otherwise(None)
            )

    # In l·∫°i schema x√°c nh·∫≠n
    # df.printSchema()
    return df

def compute_mode(df, col):
    # H√†m t√≠nh gi√° tr·ªã mode (gi√° tr·ªã xu·∫•t hi·ªán nhi·ªÅu nh·∫•t) c·ªßa m·ªôt c·ªôt

    mode_row = df.groupBy(col).count().orderBy(F.desc("count")).first()
    return mode_row[col] if mode_row else None

def pre_eda():
    resolve_csv_path()
    raw_data= load_data()
    df = cast_numeric_columns(raw_data)
    return df



def describe_numeric_columns(df):
    os.makedirs("reports/numeric_cols", exist_ok=True)

    known_numerical_cols = [f.name for f in df.schema.fields
                            if f.dataType.simpleString() in ("double", "int", "float", "long")]

    numerical_cols = [c for c in known_numerical_cols if c in df.columns]

    for col_name in numerical_cols:
        df = df.withColumn(col_name,
            when(F.col(col_name).rlike(r"^-?\d+(\.\d+)?$"), F.col(col_name).cast("double")).otherwise(None)
        )

    print(" ƒê√£ √©p ki·ªÉu an to√†n cho c√°c c·ªôt s·ªë:", numerical_cols)

    summary_results = []

    for col_name in numerical_cols:
        print(f"\n Th·ªëng k√™ m√¥ t·∫£ cho c·ªôt: {col_name}")
        summary_df = df.select(col_name).summary("count", "mean", "stddev", "min", "max")
        pdf = summary_df.toPandas()
        pdf.insert(0, "column", col_name)
        summary_results.append(pdf)

    final_summary = pd.concat(summary_results, ignore_index=True)

    # GUI: ch·ªçn n∆°i l∆∞u
    root = tk.Tk()
    root.withdraw()

    save_path = filedialog.asksaveasfilename(
        title="L∆∞u th·ªëng k√™ m√¥ t·∫£ c√°c c·ªôt s·ªë",
        defaultextension=".csv",
        filetypes=[("CSV files", "*.csv")],
        initialfile="numeric_summary.csv",
        initialdir="reports/numeric_cols"
    )

    if save_path:
        final_summary.to_csv(save_path, index=False)
        print(f" ƒê√£ l∆∞u th·ªëng k√™ m√¥ t·∫£ c√°c c·ªôt s·ªë t·∫°i: {save_path}")
        messagebox.showinfo("Th√†nh c√¥ng", f"ƒê√£ l∆∞u file t·∫°i:\n{save_path}")
    else:
        print(" Ng∆∞·ªùi d√πng ƒë√£ h·ªßy l∆∞u file.")



def describe_extended(df):
    os.makedirs("reports/extended_describe_numeric_cols", exist_ok=True)

    numerical_cols = [
        "price", "num_subscribers", "avg_rating", "num_reviews",
        "num_comments", "num_lectures", "content_length_min", "most_common_price"
    ]
    available_cols = [c for c in numerical_cols if c in df.columns]

    results = []

    for col in available_cols:
        print(f"üìä ƒêang t√≠nh th·ªëng k√™ cho: {col}")
        approx = df.approxQuantile(col, [0.25, 0.5, 0.75], 0.01)
        q1, median, q3 = approx if len(approx) == 3 else (None, None, None)
        iqr = q3 - q1 if q3 is not None and q1 is not None else None
        mode = compute_mode(df, col)

        agg = df.agg(
            F.count(col).alias("count"),
            F.mean(col).alias("mean"),
            F.stddev(col).alias("stddev"),
            F.min(col).alias("min"),
            F.max(col).alias("max"),
            F.countDistinct(col).alias("unique")
        ).collect()[0]

        results.append({
            "column": col,
            "count": agg["count"],
            "mean": agg["mean"],
            "stddev": agg["stddev"],
            "min": agg["min"],
            "max": agg["max"],
            "unique": agg["unique"],
            "q1": q1,
            "median": median,
            "q3": q3,
            "iqr": iqr,
            "mode": mode
        })

    result_df = pd.DataFrame(results)

    root = tk.Tk()
    root.withdraw()

    save_path = filedialog.asksaveasfilename(
        title="L∆∞u k·∫øt qu·∫£ th·ªëng k√™ m√¥ t·∫£ m·ªü r·ªông",
        defaultextension=".csv",
filetypes=[("CSV files", "*.csv")],
        initialfile="summary_stats.csv",
        initialdir="reports/extended_describe_numeric_cols"
    )

    if save_path:
        result_df.to_csv(save_path, index=False)
        print(f" ƒê√£ l∆∞u th·ªëng k√™ m√¥ t·∫£ m·ªü r·ªông t·∫°i: {save_path}")
        messagebox.showinfo("Th√†nh c√¥ng", f"ƒê√£ l∆∞u file t·∫°i:\n{save_path}")
    else:
        print(" Ng∆∞·ªùi d√πng ƒë√£ h·ªßy l∆∞u file.")



# Li·ªáu m·ª©c gi√° cao/th·∫•p ·∫£nh h∆∞·ªüng ƒë·∫øn quy·∫øt ƒë·ªãnh mua
def price_effect_on_result(df):
    # Chuy·ªÉn DataFrame t·ª´ Spark v·ªÅ pandas
    df_pd = df.select("price", "result").dropna().toPandas()

    # T·∫°o c√°c bins theo kho·∫£ng gi√°
    price_bins = [0, 20, 50, 100, 200, 500, 1000]
    df_pd["price_bin"] = pd.cut(df_pd["price"], bins=price_bins)

    # T√≠nh t·ª∑ l·ªá mua trung b√¨nh theo kho·∫£ng gi√°
    price_group = df_pd.groupby("price_bin")["result"].mean().reset_index()

    # V·∫Ω barplot
    plt.figure(figsize=(10, 6))
    sns.barplot(x="price_bin", y="result", data=price_group)
    plt.title("T·ª∑ l·ªá mua theo kho·∫£ng gi√° kh√≥a h·ªçc")
    plt.xlabel("Kho·∫£ng gi√° (USD)")
    plt.ylabel("T·ª∑ l·ªá mua (mean result)")
    plt.grid(True)
    plt.tight_layout()


    # import pandas as pd
    # import matplotlib.pyplot as plt
    # import seaborn as sns

    # Chuy·ªÉn t·ª´ Spark DataFrame sang pandas v√† lo·∫°i b·ªè gi√° tr·ªã thi·∫øu
    df_pd = df.select("price", "result").dropna().toPandas()
    plt.show()


# In[ ]:


# Kh√≥a h·ªçc c√≥ nhi·ªÅu ng∆∞·ªùi ƒëƒÉng k√Ω th√¨ c√≥ t·ª∑ l·ªá mua cao h∆°n kh√¥ng?
def num_subscribers_effect_on_result(df):
    # L·ªçc d·ªØ li·ªáu: lo·∫°i b·ªè outliers c√≥ num_subscribers qu√° cao
    df_pd = df.select("num_subscribers", "result").dropna().toPandas()
    df_pd_filtered = df_pd[df_pd["num_subscribers"] < 50000]



    # T·∫°o bi·ªÉu ƒë·ªì histogram ph√¢n nh√≥m theo h√†nh vi mua
    plt.figure(figsize=(10, 6))
    sns.histplot(
        data=df_pd_filtered,
        x="num_subscribers",
        hue="result",
        bins=50,
        kde=True,
        element="step",
        stat="density",
        common_norm=False
    )

    # Th√™m nh√£n v√† ch√∫ th√≠ch
    plt.title("M·ªëi li√™n h·ªá gi·ªØa s·ªë ng∆∞·ªùi ƒëƒÉng k√Ω v√† t·ª∑ l·ªá mua kh√≥a h·ªçc")
    plt.xlabel("S·ªë ng∆∞·ªùi ƒëƒÉng k√Ω kh√≥a h·ªçc")
    plt.ylabel("T·ª∑ l·ªá mua kh√≥a h·ªçc (density)")
    plt.legend(title="H√†nh vi mua kh√≥a h·ªçc", labels=["Kh√¥ng mua (0)", "ƒê√£ mua (1)"])
    plt.grid(True)
    plt.tight_layout()
    plt.show()


# In[ ]:


# Rating ·∫£nh h∆∞·ªüng ƒë·∫øn t·ª∑ l·ªá mua kh√≥a h·ªçc nh∆∞ th·∫ø n√†o?
def avg_rating_effect_on_result(df):
    # Chuy·ªÉn t·ª´ Spark sang pandas
    df_pd = df.select("avg_rating", "result").dropna().toPandas()

    # Gi·ªõi h·∫°n avg_rating h·ª£p l·ªá trong [0, 5]
    df_pd = df_pd[(df_pd["avg_rating"] >= 0) & (df_pd["avg_rating"] <= 5)]

    # Chia th√†nh c√°c kho·∫£ng rating: 0.0‚Äì0.5, 0.5‚Äì1.0, ..., 4.5‚Äì5.0
    rating_bins = [round(x * 0.5, 1) for x in range(11)]  # [0.0, 0.5, ..., 5.0]
    df_pd["rating_bin"] = pd.cut(df_pd["avg_rating"], bins=rating_bins, right=False)

    # T√≠nh t·ª∑ l·ªá mua trung b√¨nh trong t·ª´ng nh√≥m
    grouped = df_pd.groupby("rating_bin")["result"].mean().reset_index()

    # V·∫Ω bi·ªÉu ƒë·ªì c·ªôt
    plt.figure(figsize=(10, 5))
    sns.barplot(data=grouped, x="rating_bin", y="result", palette="Blues_d")
    plt.title("T·ª∑ l·ªá mua theo nh√≥m ƒëi·ªÉm ƒë√°nh gi√° (avg_rating)")
    plt.xlabel("Kho·∫£ng ƒëi·ªÉm ƒë√°nh gi√°")
    plt.ylabel("T·ª∑ l·ªá mua trung b√¨nh")
    plt.grid(axis="y", linestyle="--", alpha=0.7)
    plt.tight_layout()
    plt.show()


# In[19]:


# ƒê·ªô d√†i kho√° h·ªçc ·∫£nh h∆∞·ªüng ƒë·∫øn tyÃâ l·ªá mua kh√≥a h·ªçc nh∆∞ th·∫ø n√†o?
def content_length_min_effect_on_result(df):
    # Chuy·ªÉn t·ª´ Spark v·ªÅ pandas v√† l√†m s·∫°ch
    df_pd = df.select("content_length_min", "result").dropna().toPandas()
    df_pd = df_pd[df_pd["content_length_min"] > 0]

    # Chuy·ªÉn ph√∫t sang gi·ªù cho d·ªÖ hi·ªÉu
    df_pd["content_length_hr"] = df_pd["content_length_min"] / 60

    # ƒê·ªãnh nghƒ©a c√°c bins ƒë·ªô d√†i (t√≠nh theo gi·ªù)
    bins = [0, 0.5, 1, 2, 5, 10, 1000]  # t·ª´ 0 ƒë·∫øn 1000 gi·ªù
    labels = ["<30 min", "30-60 min", "1-2 hr", "2-5 hr", "5-10 hr", ">10 hr"]
    df_pd["length_group"] = pd.cut(df_pd["content_length_hr"], bins=bins, labels=labels)

    # T√≠nh t·ª∑ l·ªá mua theo t·ª´ng nh√≥m ƒë·ªô d√†i
    grouped = df_pd.groupby("length_group")["result"].mean().reset_index()

    # V·∫Ω bi·ªÉu ƒë·ªì
    plt.figure(figsize=(10, 5))
    sns.barplot(data=grouped, x="length_group", y="result", palette="Greens_d")
    plt.title("T·ª∑ l·ªá mua theo ƒë·ªô d√†i kh√≥a h·ªçc (theo gi·ªù)")
    plt.xlabel("Nh√≥m ƒë·ªô d√†i")
    plt.ylabel("T·ª∑ l·ªá mua trung b√¨nh")
    plt.grid(axis="y", linestyle="--", alpha=0.7)
    plt.tight_layout()
    plt.show()


# In[23]:


# C√≥ ph·∫£i review c√†ng nhi·ªÅu th√¨ rating c√†ng cao?
def num_reviews_effect_on_avg_rating(df):
    # Chuy·ªÉn d·ªØ li·ªáu sang pandas v√† lo·∫°i b·ªè NA, outliers
    df_pd = df.select("num_reviews", "avg_rating").dropna().toPandas()
    df_pd = df_pd[(df_pd["num_reviews"] > 0) & (df_pd["num_reviews"] < 10000) & 
                (df_pd["avg_rating"] > 0) & (df_pd["avg_rating"] <= 5)]

    # V·∫Ω scatter + ƒë∆∞·ªùng h·ªìi quy
    plt.figure(figsize=(10, 6))
    sns.regplot(data=df_pd, x="num_reviews", y="avg_rating",
                scatter_kws={"alpha": 0.3, "s": 20}, line_kws={"color": "red"})

    # T√≠nh v√† hi·ªÉn th·ªã h·ªá s·ªë t∆∞∆°ng quan Pearson
    corr = df_pd["num_reviews"].corr(df_pd["avg_rating"])
    plt.text(8000, 4.3, f"H·ªá s·ªë t∆∞∆°ng quan : {corr:.3f}", color="red", fontsize=10,
            bbox=dict(facecolor="white", edgecolor="red", alpha=0.4))

    # Th√™m ti√™u ƒë·ªÅ v√† nh√£n
    plt.title("M·ªëi quan h·ªá gi·ªØa s·ªë l∆∞·ª£ng review v√† ƒëi·ªÉm rating trung b√¨nh", fontsize=14, weight="bold")
    plt.xlabel("S·ªë l∆∞·ª£ng review")
    plt.ylabel("ƒêi·ªÉm ƒë√°nh gi√° trung b√¨nh")
    plt.grid(True, linestyle="--", alpha=0.6)
    plt.tight_layout()
    plt.show()


# In[24]:


# Ph√¢n t√≠ch ·∫£nh h∆∞·ªüng c·ªßa s·ªë l∆∞·ª£ng review ƒë·∫øn quy·∫øt ƒë·ªãnh mua
def num_reviews_effect_on_result(df):
    # Chuy·ªÉn t·ª´ Spark v·ªÅ pandas v√† l·ªçc d·ªØ li·ªáu b·∫•t th∆∞·ªùng
    df_pd = df.select("num_reviews", "result").dropna().toPandas()
    df_pd = df_pd[(df_pd["num_reviews"] >= 0) & (df_pd["num_reviews"] < 5000)]  # l·ªçc outlier

    # Chia nh√≥m review theo kho·∫£ng
    bins = [0, 10, 50, 100, 200, 500, 1000, 5000]
    labels = ["<10", "10-50", "50-100", "100-200", "200-500", "500-1000", "1000-5000"]
    df_pd["review_group"] = pd.cut(df_pd["num_reviews"], bins=bins, labels=labels)

    # T√≠nh t·ª∑ l·ªá mua trung b√¨nh theo t·ª´ng nh√≥m
    grouped = df_pd.groupby("review_group")["result"].mean().reset_index()

    # V·∫Ω bi·ªÉu ƒë·ªì
    plt.figure(figsize=(10, 5))
    sns.barplot(data=grouped, x="review_group", y="result", palette="Blues_d")
    plt.title("T·ª∑ l·ªá mua theo s·ªë l∆∞·ª£ng review", fontsize=14, weight="bold")
    plt.xlabel("Nh√≥m s·ªë l∆∞·ª£ng review")
    plt.ylabel("T·ª∑ l·ªá mua trung b√¨nh")
    plt.grid(axis="y", linestyle="--", alpha=0.7)
    plt.tight_layout()
    plt.show()


# In[26]:


# M·ªëi t∆∞∆°ng quan n√†o gi·ªØa gi√° c·ªßa kh√≥a h·ªçc v√† s·ªë l∆∞·ª£ng b√†i gi·∫£ng
def price_effect_on_num_lectures(df):
    # Chuy·ªÉn d·ªØ li·ªáu sang pandas
    df_pd = df.select("price", "num_lectures").dropna().toPandas()

    # L·ªçc outlier nh·∫π: ch·ªâ gi·ªØ c√°c kho√° h·ªçc d∆∞·ªõi 500 b√†i gi·∫£ng v√† gi√° < 500$
    df_pd = df_pd[(df_pd["price"] < 500) & (df_pd["num_lectures"] < 500)]

    # V·∫Ω scatter plot + ƒë∆∞·ªùng xu h∆∞·ªõng
    plt.figure(figsize=(10, 6))
    sns.regplot(data=df_pd, x="num_lectures", y="price",
                scatter_kws={"alpha": 0.3, "s": 20}, line_kws={"color": "red"})
    plt.title("M·ªëi quan h·ªá gi·ªØa s·ªë b√†i gi·∫£ng v√† gi√° kh√≥a h·ªçc", fontsize=14, weight="bold")
    plt.xlabel("S·ªë b√†i gi·∫£ng")
    plt.ylabel("Gi√° kh√≥a h·ªçc ($)")
    plt.grid(True, linestyle="--", alpha=0.6)

    # Th√™m ch√∫ th√≠ch
    plt.text(300, 400, "ƒê∆∞·ªùng ƒë·ªè th·ªÉ hi·ªán xu h∆∞·ªõng:\nKho√° h·ªçc nhi·ªÅu b√†i gi·∫£ng th∆∞·ªùng c√≥ gi√° cao h∆°n",
            color="red", fontsize=10, bbox=dict(facecolor='white', edgecolor='red', alpha=0.3))

    plt.tight_layout()
    plt.show()